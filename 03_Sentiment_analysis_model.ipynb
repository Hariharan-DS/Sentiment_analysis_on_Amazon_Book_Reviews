{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "62a0a282-4b1f-40cc-99de-f104e8bed8d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: /libraries/llm_gpu_mistral/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      "Requirement already satisfied: transformers in /libraries/llm_gpu_mistral/lib/python3.9/site-packages (4.34.0.dev0)\n",
      "Requirement already satisfied: datasets in /libraries/llm_gpu_mistral/lib/python3.9/site-packages (2.14.5)\n",
      "Requirement already satisfied: scikit-learn in /libraries/llm_gpu_mistral/lib/python3.9/site-packages (1.3.0)\n",
      "Requirement already satisfied: torch in /libraries/llm_gpu_mistral/lib/python3.9/site-packages (2.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /libraries/llm_gpu_mistral/lib/python3.9/site-packages (from transformers) (2023.8.8)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /libraries/llm_gpu_mistral/lib/python3.9/site-packages (from transformers) (0.16.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /libraries/llm_gpu_mistral/lib/python3.9/site-packages (from transformers) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /libraries/llm_gpu_mistral/lib/python3.9/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /libraries/llm_gpu_mistral/lib/python3.9/site-packages (from transformers) (0.3.3)\n",
      "Requirement already satisfied: requests in /libraries/llm_gpu_mistral/lib/python3.9/site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /libraries/llm_gpu_mistral/lib/python3.9/site-packages (from transformers) (4.65.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /libraries/llm_gpu_mistral/lib/python3.9/site-packages (from transformers) (1.23.5)\n",
      "Requirement already satisfied: filelock in /libraries/llm_gpu_mistral/lib/python3.9/site-packages (from transformers) (3.12.4)\n",
      "Requirement already satisfied: tokenizers<0.15,>=0.14 in /libraries/llm_gpu_mistral/lib/python3.9/site-packages (from transformers) (0.14.0)\n",
      "Requirement already satisfied: xxhash in /libraries/llm_gpu_mistral/lib/python3.9/site-packages (from datasets) (3.3.0)\n",
      "Requirement already satisfied: multiprocess in /libraries/llm_gpu_mistral/lib/python3.9/site-packages (from datasets) (0.70.15)\n",
      "Requirement already satisfied: aiohttp in /libraries/llm_gpu_mistral/lib/python3.9/site-packages (from datasets) (3.8.5)\n",
      "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /libraries/llm_gpu_mistral/lib/python3.9/site-packages (from datasets) (0.3.7)\n",
      "Requirement already satisfied: fsspec[http]<2023.9.0,>=2023.1.0 in /libraries/llm_gpu_mistral/lib/python3.9/site-packages (from datasets) (2023.6.0)\n",
      "Requirement already satisfied: pandas in /libraries/llm_gpu_mistral/lib/python3.9/site-packages (from datasets) (2.1.1)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /libraries/llm_gpu_mistral/lib/python3.9/site-packages (from datasets) (13.0.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /libraries/llm_gpu_mistral/lib/python3.9/site-packages (from scikit-learn) (3.2.0)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /libraries/llm_gpu_mistral/lib/python3.9/site-packages (from scikit-learn) (1.3.1)\n",
      "Requirement already satisfied: scipy>=1.5.0 in /libraries/llm_gpu_mistral/lib/python3.9/site-packages (from scikit-learn) (1.11.2)\n",
      "Requirement already satisfied: typing-extensions in /libraries/llm_gpu_mistral/lib/python3.9/site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: sympy in /libraries/llm_gpu_mistral/lib/python3.9/site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in /libraries/llm_gpu_mistral/lib/python3.9/site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in /libraries/llm_gpu_mistral/lib/python3.9/site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /libraries/llm_gpu_mistral/lib/python3.9/site-packages (from aiohttp->datasets) (3.2.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /libraries/llm_gpu_mistral/lib/python3.9/site-packages (from aiohttp->datasets) (6.0.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /libraries/llm_gpu_mistral/lib/python3.9/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /libraries/llm_gpu_mistral/lib/python3.9/site-packages (from aiohttp->datasets) (23.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /libraries/llm_gpu_mistral/lib/python3.9/site-packages (from aiohttp->datasets) (1.9.2)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /libraries/llm_gpu_mistral/lib/python3.9/site-packages (from aiohttp->datasets) (4.0.3)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /libraries/llm_gpu_mistral/lib/python3.9/site-packages (from aiohttp->datasets) (1.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /libraries/llm_gpu_mistral/lib/python3.9/site-packages (from requests->transformers) (2023.7.22)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /libraries/llm_gpu_mistral/lib/python3.9/site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /libraries/llm_gpu_mistral/lib/python3.9/site-packages (from requests->transformers) (1.26.16)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /libraries/llm_gpu_mistral/lib/python3.9/site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /libraries/llm_gpu_mistral/lib/python3.9/site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /libraries/llm_gpu_mistral/lib/python3.9/site-packages (from pandas->datasets) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /libraries/llm_gpu_mistral/lib/python3.9/site-packages (from pandas->datasets) (2023.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /libraries/llm_gpu_mistral/lib/python3.9/site-packages (from sympy->torch) (1.3.0)\n",
      "Requirement already satisfied: six>=1.5 in /libraries/llm_gpu_mistral/lib/python3.9/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install transformers datasets scikit-learn torch datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e796f89c-44f9-419c-9f6e-5566e13c56a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: /libraries/llm_gpu_mistral/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      "Thu Dec  5 12:35:29 2024       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.183.01             Driver Version: 535.183.01   CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  Tesla V100-SXM2-16GB           Off | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   33C    P0              32W / 300W |      0MiB / 16384MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   1  Tesla V100-SXM2-16GB           Off | 00000000:00:05.0 Off |                    0 |\n",
      "| N/A   33C    P0              34W / 300W |      0MiB / 16384MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|  No running processes found                                                           |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "82c79164-90ef-4f30-b06d-b24112f7a365",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from mlutils import connector\n",
    "import io\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datasets import Dataset\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "import os\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "17c2878a-13fc-4fcf-afcf-24e3f597c135",
   "metadata": {},
   "outputs": [],
   "source": [
    "connector_name = 'cat-ds-gcs'\n",
    "bucket_name = \"bucket\"\n",
    "conn = connector.get_connector(name=connector_name)\n",
    "bucket = conn.get_bucket(bucket_name)\n",
    "sampled_data_path = \"data_engg/sampled_book_df.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "04d000fa-97ba-4880-bb11-80a110165bae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['categories', 'ratingsCount', 'Title', 'Id', 'Price', 'User_id',\n",
       "       'profileName', 'review/helpfulness', 'review/score', 'review/time',\n",
       "       'review/summary', 'review/text'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob = bucket.blob(sampled_data_path)\n",
    "\n",
    "# Download the file content as bytes\n",
    "data = blob.download_as_bytes()\n",
    "\n",
    "# Use io.BytesIO to load the content into a DataFrame\n",
    "sampled_df = pd.read_csv(io.BytesIO(data))\n",
    "\n",
    "# Display the DataFrame\n",
    "sampled_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ca9de1af-5cbf-451f-a97a-2e1ae3507ec1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>categories</th>\n",
       "      <th>ratingsCount</th>\n",
       "      <th>Title</th>\n",
       "      <th>Id</th>\n",
       "      <th>Price</th>\n",
       "      <th>User_id</th>\n",
       "      <th>profileName</th>\n",
       "      <th>review/helpfulness</th>\n",
       "      <th>review/score</th>\n",
       "      <th>review/time</th>\n",
       "      <th>review/summary</th>\n",
       "      <th>review/text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AIDS (Disease)</td>\n",
       "      <td>19.0</td>\n",
       "      <td>Miracle Cure</td>\n",
       "      <td>B000J2CLPG</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A33MJKWZSQHIVS</td>\n",
       "      <td>Nevada Native</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1346544000</td>\n",
       "      <td>Not my favorite by Coben, but worth reading</td>\n",
       "      <td>I agree with Coben on this one - don't read th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AIDS (Disease)</td>\n",
       "      <td>19.0</td>\n",
       "      <td>Miracle Cure</td>\n",
       "      <td>B000J2CLPG</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A2UBD96PEJ0QSE</td>\n",
       "      <td>silver5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1323475200</td>\n",
       "      <td>Pleasant surprise!</td>\n",
       "      <td>\\When I saw this title I thought...what? I've ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AIDS (Disease)</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Get All The Facts: HIV does not cause AIDS</td>\n",
       "      <td>0967353602</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A30DOF1UJ8QHX</td>\n",
       "      <td>Betty Hyder</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>981504000</td>\n",
       "      <td>Grateful</td>\n",
       "      <td>My thanks and appreciation to Dr. Al-Bayati fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Aboriginal Australians</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Songlines (Reed Audio, 179)</td>\n",
       "      <td>186021990X</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A38BIVW2RNO3RW</td>\n",
       "      <td>\\An admirer of Saul \\\"\\\"Mr Wobble\\\"\\\"\\\"\"</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1301616000</td>\n",
       "      <td>Life is a Long Song</td>\n",
       "      <td>Part travelogue,part anthropology,part history...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Abortion</td>\n",
       "      <td>21.0</td>\n",
       "      <td>Case of Need</td>\n",
       "      <td>B000QKUCJI</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A2PZXXPGLXXKZU</td>\n",
       "      <td>Amazon Reviewer29</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1330128000</td>\n",
       "      <td>First book written by Michael Crichton</td>\n",
       "      <td>I read this book last year. I really wanted so...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               categories  ratingsCount  \\\n",
       "0          AIDS (Disease)          19.0   \n",
       "1          AIDS (Disease)          19.0   \n",
       "2          AIDS (Disease)           0.0   \n",
       "3  Aboriginal Australians           0.0   \n",
       "4                Abortion          21.0   \n",
       "\n",
       "                                        Title          Id  Price  \\\n",
       "0                                Miracle Cure  B000J2CLPG    NaN   \n",
       "1                                Miracle Cure  B000J2CLPG    NaN   \n",
       "2  Get All The Facts: HIV does not cause AIDS  0967353602    NaN   \n",
       "3                 Songlines (Reed Audio, 179)  186021990X    NaN   \n",
       "4                                Case of Need  B000QKUCJI    NaN   \n",
       "\n",
       "          User_id                               profileName  \\\n",
       "0  A33MJKWZSQHIVS                             Nevada Native   \n",
       "1  A2UBD96PEJ0QSE                                   silver5   \n",
       "2   A30DOF1UJ8QHX                               Betty Hyder   \n",
       "3  A38BIVW2RNO3RW  \\An admirer of Saul \\\"\\\"Mr Wobble\\\"\\\"\\\"\"   \n",
       "4  A2PZXXPGLXXKZU                         Amazon Reviewer29   \n",
       "\n",
       "   review/helpfulness  review/score review/time  \\\n",
       "0                 0.0           4.0  1346544000   \n",
       "1                 5.0           5.0  1323475200   \n",
       "2                 5.0           5.0   981504000   \n",
       "3                 0.0           5.0  1301616000   \n",
       "4                 5.0           3.0  1330128000   \n",
       "\n",
       "                                review/summary  \\\n",
       "0  Not my favorite by Coben, but worth reading   \n",
       "1                           Pleasant surprise!   \n",
       "2                                     Grateful   \n",
       "3                          Life is a Long Song   \n",
       "4       First book written by Michael Crichton   \n",
       "\n",
       "                                         review/text  \n",
       "0  I agree with Coben on this one - don't read th...  \n",
       "1  \\When I saw this title I thought...what? I've ...  \n",
       "2  My thanks and appreciation to Dr. Al-Bayati fo...  \n",
       "3  Part travelogue,part anthropology,part history...  \n",
       "4  I read this book last year. I really wanted so...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8db0c2c3-7c68-48d9-b9e8-03fef9055a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_df = sampled_df.dropna(subset=['review/summary', 'review/text', 'review/score'])\n",
    "sampled_df = sampled_df.assign(labels=sampled_df['review/score'].map(lambda score: 2 if score > 3.5 else (1 if score > 2.5 else 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0f49a5b9-a109-44bd-889f-7697e4897eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_df['review/text'] = sampled_df['review/text'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "857550ca-3468-4d07-bf0b-f4d974374221",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 78599 entries, 0 to 78616\n",
      "Data columns (total 13 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   categories          78599 non-null  object \n",
      " 1   ratingsCount        78599 non-null  float64\n",
      " 2   Title               78599 non-null  object \n",
      " 3   Id                  78599 non-null  object \n",
      " 4   Price               12954 non-null  float64\n",
      " 5   User_id             63406 non-null  object \n",
      " 6   profileName         63400 non-null  object \n",
      " 7   review/helpfulness  78599 non-null  float64\n",
      " 8   review/score        78599 non-null  float64\n",
      " 9   review/time         78599 non-null  object \n",
      " 10  review/summary      78599 non-null  object \n",
      " 11  review/text         78599 non-null  object \n",
      " 12  labels              78599 non-null  int64  \n",
      "dtypes: float64(4), int64(1), object(8)\n",
      "memory usage: 8.4+ MB\n"
     ]
    }
   ],
   "source": [
    "sampled_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c32a98d2-9833-4705-ac00-0dcb458ae31a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = train_test_split(sampled_df, train_size=0.8, random_state=24, stratify = sampled_df['labels'])\n",
    "rest_df, test_df = train_test_split(sampled_df, test_size=0.1, random_state=24, stratify = sampled_df['labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ac3cc14b-e6b7-4a58-a028-86e7b0279cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_df['labels'].value_counts()\n",
    "class_2 = train_df[train_df['labels'] == 2]\n",
    "class_0 = train_df[train_df['labels'] == 0]\n",
    "class_1 = train_df[train_df['labels'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5c39b555-08b8-43c7-8b73-f421b7b2f581",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "labels\n",
       "2    5208\n",
       "0    5208\n",
       "1    5208\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_class_size = min(class_0.shape[0], class_1.shape[0])\n",
    "class_2_undersampled = class_2.sample(n=min_class_size, random_state=24)\n",
    "class_0_undersampled = class_0.sample(n=min_class_size, random_state=24)\n",
    "balanced_df = pd.concat([class_2_undersampled, class_0_undersampled, class_1])\n",
    "\n",
    "balanced_df['labels'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ad059b6d-1c47-43e7-8b23-f1493a1bfbee",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Dataset.from_pandas(balanced_df)\n",
    "test_dataset = Dataset.from_pandas(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "658b6af6-41c9-4b79-98ec-0658b271d793",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading the tokenizer from the `special_tokens_map.json` and the `added_tokens.json` will be removed in `transformers 5`,  it is kept for forward compatibility, but it is recommended to update your `tokenizer_config.json` by uploading it again. You will see the new `added_tokens_decoder` attribute that will store the relevant information.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\", cache_dir=\"/data/bert_cache\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b2ebbd0a-72cc-46f8-aa54-739e8ef485d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(data):\n",
    "\n",
    "    encoding = tokenizer.encode_plus(\n",
    "        data['review/text'],\n",
    "        max_length=512,\n",
    "        truncation=True,\n",
    "        padding='max_length',\n",
    "        return_tensors='pt',\n",
    "        add_special_tokens=True\n",
    "    )\n",
    "\n",
    "    return {\n",
    "        'input_ids': encoding['input_ids'].squeeze(0),  # Remove batch dimension (if necessary)\n",
    "        'attention_mask': encoding['attention_mask'].squeeze(0),  # Remove batch dimension (if necessary)\n",
    "        'token_type_ids': encoding.get('token_type_ids', None).squeeze(0)  # Optional: only needed for some models\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3900c2e5-0d00-4302-aff4-e1d9f151d8af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, predictions, average=\"weighted\")\n",
    "    acc = accuracy_score(labels, predictions)\n",
    "    return {\"accuracy\": acc, \"f1\": f1, \"precision\": precision, \"recall\": recall}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "26623847-dec1-4688-97e9-90549ec7b4c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 15624/15624 [00:51<00:00, 304.88 examples/s]\n",
      "Map: 100%|██████████| 7860/7860 [00:24<00:00, 314.91 examples/s]\n"
     ]
    }
   ],
   "source": [
    "train = train_dataset.map(tokenize, batched = False)\n",
    "test =  test_dataset.map(tokenize,  batched = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "57f9d7eb-b106-44a4-83fd-fa8f69c2ed57",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.set_format(type='torch', columns=['input_ids', 'attention_mask', 'token_type_ids', 'labels'])\n",
    "test.set_format(type='torch', columns=['input_ids', 'attention_mask', 'token_type_ids', 'labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bd7ccff1-74bf-4b76-9411-9af7ebc55253",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels = 3, cache_dir=\"/data/bert_cache\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d10ec8f6-cd11-4e51-89ea-c939f4dd1b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir='/data/results',\n",
    "    report_to=\"none\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=5e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    warmup_steps=100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c76dd30a-1477-44df-ad25-2f2f3cde3fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train,\n",
    "    eval_dataset=test,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "704976a4-d91f-44ec-9628-12e170ee1502",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/libraries/llm_gpu_mistral/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1467' max='1467' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1467/1467 14:03, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.559874</td>\n",
       "      <td>0.765522</td>\n",
       "      <td>0.801348</td>\n",
       "      <td>0.869001</td>\n",
       "      <td>0.765522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.742100</td>\n",
       "      <td>0.460087</td>\n",
       "      <td>0.821247</td>\n",
       "      <td>0.841907</td>\n",
       "      <td>0.874924</td>\n",
       "      <td>0.821247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.471300</td>\n",
       "      <td>0.739135</td>\n",
       "      <td>0.769593</td>\n",
       "      <td>0.806959</td>\n",
       "      <td>0.876398</td>\n",
       "      <td>0.769593</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/libraries/llm_gpu_mistral/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/libraries/llm_gpu_mistral/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/libraries/llm_gpu_mistral/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/libraries/llm_gpu_mistral/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1467, training_loss=0.4921753252129532, metrics={'train_runtime': 845.5652, 'train_samples_per_second': 55.433, 'train_steps_per_second': 1.735, 'total_flos': 1.2332652115746816e+16, 'train_loss': 0.4921753252129532, 'epoch': 3.0})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "004e2986-482b-4d11-b030-c9a330047b1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/libraries/llm_gpu_mistral/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='246' max='246' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [246/246 00:42]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.7106401920318604,\n",
       " 'eval_accuracy': 0.7791348600508906,\n",
       " 'eval_f1': 0.8128753912922158,\n",
       " 'eval_precision': 0.875301320898174,\n",
       " 'eval_recall': 0.7791348600508906,\n",
       " 'eval_runtime': 42.3902,\n",
       " 'eval_samples_per_second': 185.42,\n",
       " 'eval_steps_per_second': 5.803,\n",
       " 'epoch': 3.0}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "82830024-f5cc-4a61-8295-17ab1f34f598",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment for \"This book was okay, not bad but not great either.\":\n",
      "\tClass weights: tensor([[-0.5386,  3.0430, -2.0915]], device='cuda:0')\n",
      "\tSentiment : neutral\n",
      "\n",
      "\n",
      "Sentiment for \"This book was very worst and not good at all\":\n",
      "\tClass weights: tensor([[ 4.2645, -2.1315, -2.6740]], device='cuda:0')\n",
      "\tSentiment : negative\n",
      "\n",
      "\n",
      "Sentiment for \"This book is very good\":\n",
      "\tClass weights: tensor([[-1.0197, -0.6811,  1.3815]], device='cuda:0')\n",
      "\tSentiment : positive\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "input_pred = [\"This book was okay, not bad but not great either.\",\n",
    "              \"This book was very worst and not good at all\",\n",
    "              \"This book is very good\"]\n",
    "sentiment_labels = [\"negative\", \"neutral\", \"positive\"]\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "model.eval()\n",
    "\n",
    "for input in input_pred:\n",
    "    # Tokenize the review\n",
    "    inputs = tokenizer.encode_plus(\n",
    "        input,\n",
    "        max_length=512,\n",
    "        truncation=True,\n",
    "        padding='max_length',\n",
    "        return_tensors='pt',\n",
    "        add_special_tokens=True\n",
    "    )\n",
    "\n",
    "    # Move input tensors to the same device\n",
    "    for key in inputs:\n",
    "        inputs[key] = inputs[key].to(device)\n",
    "    print(f\"Sentiment for \\\"{input}\\\":\")\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits\n",
    "    print(f\"\\tClass weights: {logits}\")\n",
    "\n",
    "    # Get the predicted class (0: Negative, 1: Neutral, 2: Positive)\n",
    "    prediction = torch.argmax(logits, dim=-1).item()\n",
    "    sentiment = sentiment_labels[prediction]\n",
    "    print(f\"\\tSentiment : {sentiment}\")\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "44d4c74b-4ae7-4eb0-b9be-cd605facb725",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: /libraries/llm_gpu_mistral/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      "Mon Dec  2 18:16:10 2024       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.183.01             Driver Version: 535.183.01   CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  Tesla V100-SXM2-16GB           Off | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   39C    P0              50W / 300W |  12451MiB / 16384MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   1  Tesla V100-SXM2-16GB           Off | 00000000:00:05.0 Off |                    0 |\n",
      "| N/A   40C    P0              49W / 300W |  11283MiB / 16384MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3f39681b-9c62-431e-b36d-12ce7c90497a",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model(\"/data/sentiment_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4878fb98-6fbc-438b-9bdb-c78b8d7778bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "connector.upload(name=connector_name, container=bucket_name, target_path=\"data_engg/sentiment_model/pytorch_model.bin\", source_path=\"/data/sentiment_model/pytorch_model.bin\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "49735533-8096-4e95-a789-ddee9635efbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "connector.upload(name=connector_name, container=bucket_name, target_path=\"data_engg/sentiment_model/config.json\", source_path=\"/data/sentiment_model/config.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "54b2d59c-c2ea-487f-a9ac-559c771f04db",
   "metadata": {},
   "outputs": [],
   "source": [
    "connector.upload(name=connector_name, container=bucket_name, target_path=\"data_engg/sentiment_model/training_args.bin\", source_path=\"/data/sentiment_model/training_args.bin\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Testkernel",
   "language": "python",
   "name": "testkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
